{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5cc9840f-2cca-496c-a1c3-da95d417f8e6",
   "metadata": {},
   "source": [
    "# RooFit Basics\n",
    "\n",
    "`RooFit` is a OO analysis environment built on `ROOT`. It has a collection of classes designed to augment root for data modeling.\n",
    "\n",
    "This section covers a few of the basics of RooFit. There are many more tutorials available at this link: https://root.cern.ch/root/html600/tutorials/roofit/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df4eff0-f353-4d25-888c-a18f9accd1fe",
   "metadata": {},
   "source": [
    "## Objects\n",
    "In `RooFit`, any variable, data point, function, PDF (etc.) is represented by a c++ object, available in Python via automatic Python bindings.\n",
    "The most basic of these is the `RooRealVar`. We will create one that will represent the mass of some hypothetical particle, we name it and give it an initial starting value and range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed4564f-2add-4300-9852-571124bb9cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ROOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7639fe6a-91d8-4efd-8689-cc65bdf11dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "MH = ROOT.RooRealVar(\"MH\",\"mass of the Hypothetical Boson (H-boson) in GeV\",125,120,130)\n",
    "MH.Print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf95e3a-6fc0-411c-a7ef-989d5446d6f1",
   "metadata": {},
   "source": [
    "Ok, great. This variable is now an object we can play around with. We can access this object and modify its properties, such as its value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4884b4-45e6-4078-bbaa-a58e203eb0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "MH.setVal(130)\n",
    "MH.getVal()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c97224-be2c-4f7e-92df-ed95b64e1982",
   "metadata": {},
   "source": [
    "In particle detectors we typically do not observe this particle mass, but usually define some observable which is sensitive to this mass. We will assume we can detect and reconstruct the decay products of the H-boson and measure the invariant mass of those particles. We need to make another variable that represents that invariant mass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87bd7b5-9cbc-46d9-b987-bc4a13b80cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "mass = ROOT.RooRealVar(\"m\",\"m (GeV)\",100,80,200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c5fc68-86fa-4adf-a35c-ce2e6f253a9c",
   "metadata": {},
   "source": [
    "In the perfect world we would perfectly measure the exact mass of the particle in every single event. However, our detectors are usually far from perfect so there will be some resolution effect. We will assume the resolution of our measurement of the invariant mass is 10 GeV and call it \"sigma\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a920d081-2c30-4a22-9e44-63530d9cd283",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = ROOT.RooRealVar(\"resolution\",\"#sigma\",10,0,20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0b88c7-0250-4162-9239-b62cf8eca1c7",
   "metadata": {},
   "source": [
    "More exotic variables can be constructed out of these `RooRealVars` using `RooFormulaVars`. For example, suppose we wanted to make a function out of the variables that represented the relative resolution as a function of the hypothetical mass MH."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e0de1f-9513-47bc-b420-ba68a9db08d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "func = ROOT.RooFormulaVar(\"R\",\"@0/@1\", ROOT.RooArgList(sigma,mass))\n",
    "func.Print(\"v\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8e3f00-e1e4-43b5-9f4b-08b8b4a832a2",
   "metadata": {},
   "source": [
    "Notice how there is a list of the variables we passed (the servers or \"actual vars\"). We can now plot the function. `RooFit` has a special plotting object `RooPlot` which keeps track of the objects (and their normalisations) that we want to draw. Since `RooFit` does not know the difference between objects that are and are not dependent, we need to tell it. \n",
    "\n",
    "Right now, we have the relative resolution as $R(m,\\sigma)$, whereas we want to plot \n",
    "$R(m,\\sigma(m))$!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59c85ae-1f72-4543-b0c5-8bd4a69bf32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "can = ROOT.TCanvas()\n",
    "plot = mass.frame()\n",
    "func.plotOn(plot)\n",
    "plot.Draw()\n",
    "can.Update()\n",
    "can.Draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5353bf6-e60f-4781-b64a-56925b37c32a",
   "metadata": {},
   "source": [
    "The main objects we are interested in using from `RooFit` are *probability denisty functions* or (PDFs). We can construct the PDF,\n",
    "\n",
    "$$\n",
    "f(m|M_{H},\\sigma)\n",
    "$$\n",
    "\n",
    "as a simple Gaussian shape for example or a `RooGaussian` in `RooFit` language (think McDonald's logic, everything is a `RooSomethingOrOther`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9d953b-d612-442b-b0ee-e2a1899371e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "gauss = ROOT.RooGaussian(\"gauss\", \"f(m|M_{H},#sigma)\", mass, MH, sigma)\n",
    "gauss.Print(\"V\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f311017-5883-49ed-9f41-64c79d9625bc",
   "metadata": {},
   "source": [
    "Notice how the gaussian PDF, like the `RooFormulaVar` depends on our `RooRealVar` objects, these are its servers.  Its evaluation will depend on their values. \n",
    "\n",
    "The main difference between PDFs and Functions in RooFit is that PDFs are *automatically normalised to unitiy*, hence they represent a probability density, you don't need to normalise yourself. Lets plot it for the different values of $m$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298896b8-7a8b-4b53-9890-88ace4053007",
   "metadata": {},
   "outputs": [],
   "source": [
    "can = ROOT.TCanvas()\n",
    "plot = mass.frame()\n",
    "gauss.plotOn(plot)\n",
    "\n",
    "MH.setVal(120)\n",
    "gauss.plotOn(plot, ROOT.RooFit.LineColor(ROOT.kBlue))\n",
    "\n",
    "MH.setVal(125)\n",
    "gauss.plotOn(plot, ROOT.RooFit.LineColor(ROOT.kRed));\n",
    "\n",
    "MH.setVal(135)\n",
    "gauss.plotOn(plot, ROOT.RooFit.LineColor(ROOT.kGreen))\n",
    "\n",
    "plot.Draw()\n",
    "can.Update()\n",
    "can.Draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f01d69-a468-4475-b4b3-539ebf2c798b",
   "metadata": {},
   "source": [
    "Note that as we change the value of `MH`, the PDF gets updated at the same time.\n",
    "\n",
    "PDFs can be used to generate Monte Carlo data. One of the benefits of `RooFit` is that to do so only uses a single line of code! As before, we have to tell `RooFit` which variables to generate in (e.g which are the observables for an experiment). In this case, each of our events will be a single value of \"mass\" $m$. The arguments for the function are the set of observables, follwed by the number of events,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed47e570-9b65-45b7-ade0-64107c47c49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_data = gauss.generate(ROOT.RooArgSet(mass), 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1df0394-5994-44e9-92f9-15b2d61429e3",
   "metadata": {},
   "source": [
    "Now we can plot the data as with other RooFit objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56dd080-0fc2-47fc-ad28-10ae7ac703b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "can = ROOT.TCanvas()\n",
    "plot = mass.frame()\n",
    "\n",
    "gen_data.plotOn(plot)\n",
    "gauss.plotOn(plot)\n",
    "gauss.paramOn(plot)\n",
    "\n",
    "plot.Draw()\n",
    "can.Update()\n",
    "can.Draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b890cfb-dfbf-4662-bcfb-721d24a1965b",
   "metadata": {},
   "source": [
    "Of course we are not in the business of generating MC events, but collecting *real data!*. Next we will look at using real data in `RooFit`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573513a5-c679-4c05-9d9d-f1fb6b4d1b99",
   "metadata": {},
   "source": [
    "## Datasets\n",
    "\n",
    "A dataset is essentially just a collection of points in N-dimensional (N-observables) space. There are two basic implementations in `RooFit`, \n",
    "\n",
    "1) an \"unbinned\" dataset - `RooDataSet`\n",
    "\n",
    "2) a \"binned\" dataset - `RooDataHist`\n",
    "\n",
    "both of these use the same basic structure as below"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7b5774-8258-41aa-96df-b9490aaa5bb5",
   "metadata": {},
   "source": [
    "![Alt Text](https://raw.githubusercontent.com/cms-analysis/HiggsAnalysis-CombinedLimit/main/docs/part5/images/datastructure.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298598b8-4d9b-4b51-9894-4a9411e9bec6",
   "metadata": {},
   "source": [
    "We will create an empty dataset where the only observable is the mass. Points can be added to the dataset one by one..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b09526-0905-4359-8acb-1631ce9332d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata = ROOT.RooDataSet(\"dummy\",\"My dummy dataset\", ROOT.RooArgSet(mass)) # We've made a dataset with one observable (mass)\n",
    "\n",
    "mass.setVal(123.4)\n",
    "mydata.add(ROOT.RooArgSet(mass))\n",
    "mass.setVal(145.2)\n",
    "mydata.add(ROOT.RooArgSet(mass))\n",
    "mass.setVal(170.8)\n",
    "mydata.add(ROOT.RooArgSet(mass))\n",
    "\n",
    "mydata.Print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6baf1b86-ae66-4564-bb19-d9421fbede03",
   "metadata": {},
   "source": [
    "There are also other ways to manipulate datasets in this way as shown in the diagram below\n",
    "![Alt Text](https://raw.githubusercontent.com/cms-analysis/HiggsAnalysis-CombinedLimit/main/docs/part5/images/datasets_manip.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354c7875-f7b1-4045-9907-b77491379f11",
   "metadata": {},
   "source": [
    "Luckily there are also Constructors for a `RooDataSet` from a `TTree` and for a `RooDataHist` from a `TH1` so its simple to convert from your usual ROOT objects.\n",
    "\n",
    "We will take an example dataset put together already. The file `tutorial.root` can be downloaded [here](https://github.com/amarini/Prefit2020/blob/master/Session%201/tutorial.root) and is also available in `./`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4980584-96f5-44e5-a5c2-b593cbdbe66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = ROOT.TFile.Open(\"tutorial.root\")\n",
    "file.ls()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f6871f-e619-4a3c-860e-7fdef48252ae",
   "metadata": {},
   "source": [
    "Inside the file, there is something called a `RooWorkspace`. This is just the `RooFit` way of keeping a persistent link between the objects for a model. It is a very useful way to share data and PDFs/functions etc among CMS collaborators.\n",
    "\n",
    "We will now take a look at it. It contains a `RooDataSet` and one variable. This time we called our variable (or observable) `CMS_hgg_mass`, we will assume that this is the invariant mass of photon pairs where we assume our H-boson decays to photons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5961c797-3c95-416a-b648-0d5b6fbdb411",
   "metadata": {},
   "outputs": [],
   "source": [
    "wspace = file.Get(\"workspace\")\n",
    "wspace.Print(\"v\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b5a483-4459-4772-9ce1-e36b2c69bc67",
   "metadata": {},
   "source": [
    "Now we will have a look at the data. The `RooWorkspace` has several accessor functions, we will use the `RooWorkspace::data` one. \n",
    "There are also `RooWorkspace::var`, `RooWorkspace::function` and `RooWorkspace::pdf` with (hopefully) obvious purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c104c101-1b01-49dc-b7ab-46bb3da16fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "hgg_data = wspace.data(\"dataset\")\n",
    "hgg_mass = wspace.var(\"CMS_hgg_mass\")\n",
    "\n",
    "plot = hgg_mass.frame()\n",
    "\n",
    "hgg_data.plotOn(plot, ROOT.RooFit.Binning(160))\n",
    "\n",
    "can = ROOT.TCanvas()\n",
    "plot.Draw()\n",
    "can.Update()\n",
    "can.Draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "585a048b-a417-49bf-87ba-107b7f9fc5ea",
   "metadata": {},
   "source": [
    "## Likelihoods and Fitting to data \n",
    "\n",
    "The data we have in our file does not look like a Gaussian distribution. Instead, we could probably use something like an exponential to describe it. \n",
    "\n",
    "There is an exponential PDF already in `RooFit` (yes, you guessed it) `RooExponential`. For a PDF, we only need one parameter which is the exponential slope $\\alpha$ so our pdf is,  \n",
    "\n",
    "$$ f(m|\\alpha) = \\dfrac{1}{N} e^{-\\alpha m}$$\n",
    "\n",
    "\n",
    "Where of course, $N = \\int_{110}^{150} e^{-\\alpha m} dm$ is the normalisation constant.\n",
    "\n",
    "You can find several available `RooFit` functions here: [https://root.cern.ch/root/html/ROOFIT_ROOFIT_Index.html](https://root.cern.ch/root/html/ROOFIT_ROOFIT_Index.html)\n",
    "\n",
    "There is also support for a generic PDF in the form of a `RooGenericPdf`, check this link: [https://root.cern.ch/doc/v608/classRooGenericPdf.html](https://root.cern.ch/doc/v608/classRooGenericPdf.html)\n",
    "\n",
    "Now we will create an exponential PDF for our background,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dbba2f3-ccf3-4451-92e8-8960857cdd59",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = ROOT.RooRealVar(\"alpha\", \"#alpha\", -0.05, -0.2, 0.01)\n",
    "expo = ROOT.RooExponential(\"exp\",\"exponential function\", hgg_mass, alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455ba527-1862-4da8-9da1-a6d088ab0866",
   "metadata": {},
   "source": [
    "We can use `RooFit` to tell us to estimate the value of $\\alpha$ using this dataset. You will learn more about parameter estimation, but for now we will just assume you know about maximizing likelihoods. This *maximum likelihood estimator* is common in HEP and is known to give unbiased estimates for things like distribution means etc. \n",
    "\n",
    "This also introduces the other main use of PDFs in `RooFit`. They can be used to construct *likelihoods* easily.\n",
    "\n",
    "The likelihood $\\mathcal{L}$ is defined for a particluar dataset (and model) as being proportional to the probability to observe the data assuming some pdf. For our data, the probability to observe an event with a value in an interval bounded by a and b is given by,\n",
    "\n",
    "$$ P\\left(m~\\epsilon~[a,b] \\right) = \\int_{a}^{b} f(m|\\alpha)dm  $$\n",
    "\n",
    "\n",
    "As that interval shrinks we can say this probability just becomes equal to $f(m|\\alpha)dm$.\n",
    "\n",
    "The probability to observe the dataset we have is given by the product of such probabilities for each of our data points, so that \n",
    "\n",
    "$$\\mathcal{L}(\\alpha) \\propto \\prod_{i} f(m_{i}|\\alpha)$$\n",
    "\n",
    "Note that for a specific dataset, the $dm$ factors which should be there are constnant. They can therefore be absorbed into the constant of proportionality!\n",
    "\n",
    "The maximum likelihood esitmator for $\\alpha$, usually written as $\\hat{\\alpha}$, is found by maximising $\\mathcal{L}(\\alpha)$.\n",
    "\n",
    "Note that this will not depend on the value of the constant of proportionality so we can ignore it. This is true in most scenarios because usually only the *ratio* of likelihoods is needed, in which the constant factors out. \n",
    "\n",
    "Obviously this multiplication of exponentials can lead to very large (or very small) numbers which can lead to numerical instabilities. To avoid this, we can take logs of the likelihood. Its also common to multiply this by -1 and minimize the resulting **N**egative **L**og **L**ikelihood : $\\mathrm{-Log}\\mathcal{L}(\\alpha)$.\n",
    "\n",
    "`RooFit` can construct the **NLL** for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845edc9d-f4d1-404f-962d-3bac21eb7c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "nll = expo.createNLL(hgg_data)\n",
    "nll.Print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f111e8-8d73-442d-a12f-e952bf7391bf",
   "metadata": {},
   "source": [
    "Notice that the NLL object knows which RooRealVar is the parameter because it doesn't find that one in the dataset. This is how `RooFit` distiguishes between *observables* and *parameters*.\n",
    "\n",
    "`RooFit` has an interface to Minuit via the `RooMinimizer` class which takes the NLL as an argument. To minimize, we just call the `RooMinimizer::minimize()` function. **`Minuit2`** is the program and **`migrad`** is the minimization routine which uses gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66616a20-b3b8-4b4e-b822-0a7d01ce38cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "minim = ROOT.RooMinimizer(nll)\n",
    "minim.minimize(\"Minuit2\", \"migrad\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5993ee3-729e-4947-9870-7f4fe192f2b3",
   "metadata": {},
   "source": [
    "`RooFit` has found the best fit value of alpha for this dataset. It also estimates an uncertainty on alpha using the Hessian matrix from the fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2990aaa2-f041-438a-b133-10ee28791c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha.Print(\"v\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef02af2-0535-4405-8f95-0809b09900a0",
   "metadata": {},
   "source": [
    "We will plot the resulting exponential on top of the data. Notice that the value of $\\hat{\\alpha}$ is used for the exponential."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a731c03-7c90-462b-8232-167936241612",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = hgg_mass.frame()\n",
    "hgg_data.plotOn(plot, ROOT.RooFit.Binning(160))\n",
    "expo.plotOn(plot)\n",
    "expo.paramOn(plot)\n",
    "\n",
    "can = ROOT.TCanvas()\n",
    "plot.Draw()\n",
    "can.Update()\n",
    "can.Draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf50a552-0b4a-439d-8478-71db566ad990",
   "metadata": {},
   "source": [
    "It looks like there could be a small region near 125 GeV for which our fit does not quite go through the points. Maybe our hypothetical H-boson is not so hypothetical after all!\n",
    "\n",
    "We will now see what happens if we include some resonant signal into the fit. We can take our Gaussian function again and use that as a signal model. A reasonable value for the resolution of a resonant signal with a mass around 125 GeV decaying to a pair of photons is around a GeV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e3001b-df2f-40e8-9c64-72d3708976af",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma.setVal(1.)\n",
    "sigma.setConstant()\n",
    "\n",
    "MH.setVal(125)\n",
    "MH.setConstant()\n",
    "\n",
    "hgg_signal = ROOT.RooGaussian(\"signal\", \"Gaussian PDF\", hgg_mass, MH, sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4140db76-0edf-4c3c-b36c-3b04fe065f34",
   "metadata": {},
   "source": [
    "By setting these parameters constant, `RooFit` knows (either when creating the NLL by hand or when using `fitTo`) that there is not need to fit for these parameters. \n",
    "\n",
    "We need to add this to our exponential model and fit a \"Sigmal+Background model\" by creating a `RooAddPdf`. In `RooFit` there are two ways to add PDFs, recursively where the fraction of yields for the signal and background is a parameter or absolutely where each PDF has its own normalization. We're going to use the second one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af8277d-87c7-4ac1-a74c-32a08b0a365e",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_s = ROOT.RooRealVar(\"norm_s\",\"N_{s}\",10,100)\n",
    "norm_b = ROOT.RooRealVar(\"norm_b\",\"N_{b}\",0,1000)\n",
    "\n",
    "components = ROOT.RooArgList(hgg_signal,expo)\n",
    "coeffs = ROOT.RooArgList(norm_s,norm_b)\n",
    "\n",
    "model = ROOT.RooAddPdf(\"model\",\"f_{s+b}\",components,coeffs)\n",
    "model.Print(\"v\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0852ac95-58a2-4da3-874b-fc24f5036725",
   "metadata": {},
   "source": [
    "Ok, now we will fit the model. Note this time we add the option `Extended()`, which tells `RooFit` that we care about the overall number of observed events in the data $n$ too. It will add an additional Poisson term in the likelihood to account for this so our likelihood this time looks like,\n",
    "\n",
    "$$L_{s+b}(N_{s},N_{b},\\alpha) = \\dfrac{ (N_{s}+N_{b}^{n}) e^{N_{s}+N_{b}} }{n!} \\cdot \\prod_{i}^{n} \\left[ c f_{s}(m_{i}|M_{H},\\sigma)+ (1-c)f_{b}(m_{i}|\\alpha)  \\right] $$\n",
    "\n",
    "\n",
    "where $c = \\dfrac{ N_{s} }{ N_{s} + N_{b} }$,   $f_{s}(m|M_{H},\\sigma)$ is the Gaussian signal pdf and $f_{b}(m|\\alpha)$ is the exponential pdf. Remember that $M_{H}$ and $\\sigma$ are fixed so that they are no longer parameters of the likelihood.\n",
    "\n",
    "There is a simpler interface for maximum-likelihood fits which is the `RooAbsPdf::fitTo` method. With this simple method, `RooFit` will construct the negative log-likelihood function, from the pdf, and minimize all of the free parameters in one step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ec760a-ba40-4b0b-865e-8ddf908840ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = hgg_mass.frame()\n",
    "hgg_data.plotOn(plot, ROOT.RooFit.Binning(160))\n",
    "expo.plotOn(plot)\n",
    "expo.paramOn(plot)\n",
    "\n",
    "model.fitTo(hgg_data, ROOT.RooFit.Extended())\n",
    "\n",
    "model.plotOn(plot, ROOT.RooFit.Components(\"exp\"), ROOT.RooFit.LineColor(ROOT.kGreen));\n",
    "model.plotOn(plot, ROOT.RooFit.LineColor(ROOT.kRed));\n",
    "model.paramOn(plot);\n",
    "\n",
    "can = ROOT.TCanvas()\n",
    "plot.Draw()\n",
    "can.Update()\n",
    "can.Draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36fa08c0-c1f8-4026-a78a-794aa861fe9c",
   "metadata": {},
   "source": [
    "What if we also fit for the mass ($M_{H}$)? we can easily do this by removing the constant setting on MH."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc45d21-468b-4002-9438-78c392a5a153",
   "metadata": {},
   "outputs": [],
   "source": [
    "MH.setConstant(False)\n",
    "model.fitTo(hgg_data, ROOT.RooFit.Extended())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb933a2-bc95-435d-8e28-18b17715f166",
   "metadata": {},
   "source": [
    "Notice the result for the fitted MH is not 125 and is included in the list of fitted parameters. \n",
    "We can get more information about the fit, via the `RooFitResult`, using the option `Save()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4f827c-0a55-45aa-902d-2afef1fe76b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_res = model.fitTo(hgg_data, ROOT.RooFit.Extended(), ROOT.RooFit.Save())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a31a22-d9db-41ad-9a19-bfdc63b423d4",
   "metadata": {},
   "source": [
    "For example, we can get the Correlation Matrix from the fit result... Note that the order of the parameters are the same as listed in the \"Floating Parameter\" list above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2ce5d3-3daf-43b1-aaa9-e1298291f919",
   "metadata": {},
   "outputs": [],
   "source": [
    "cormat = fit_res.correlationMatrix();\n",
    "cormat.Print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0b9a47-a5ac-4954-b5d2-b4f38a25d5de",
   "metadata": {},
   "source": [
    "A nice feature of `RooFit` is that once we have a PDF, data and results like this, we can import this new model into our `RooWorkspace` and show off our new discovery to our LHC friends (if we weren't already too late!). We can also save the \"state\" of our parameters for later, by creating a snapshot of the current values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba9fa76-e6b7-49b1-92b6-2d51d9f1c2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "getattr(wspace, \"import\")(model)  \n",
    "params = model.getParameters(hgg_data)\n",
    "wspace.saveSnapshot(\"nominal_values\", params)\n",
    "wspace.Print(\"V\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc727ca-d1f2-48b7-b842-8e22ea98a512",
   "metadata": {},
   "source": [
    "This is exactly what needs to be done when you want to use shape based datacards in <span style=\"font-variant:small-caps;\">Combine</span> with parametric models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a76371-b99f-41c5-9dd6-914b3c0d35fe",
   "metadata": {},
   "source": [
    "## A likelihood for a counting experiment\n",
    "An introductory presentation about likelihoods and interval estimation is available [here](https://indico.cern.ch/event/976099/contributions/4138517/).\n",
    "\n",
    "We have seen how to create variables and PDFs, and how to fit a PDF to data. But what if we have a counting experiment, or a histogram template shape? And what about systematic uncertainties?  We are going to build a likelihood \n",
    "for this:\n",
    "\n",
    "$\\mathcal{L} \\propto p(\\text{data}|\\text{parameters})$\n",
    "\n",
    "where our parameters are parameters of interest, $\\mu$, and nuisance parameters, $\\nu$. The nuisance parameters are constrained by external measurements, so we add constraint terms $\\pi(\\vec{\\nu}_0|\\vec{\\nu})$\n",
    "\n",
    "So we have\n",
    "$\\mathcal{L} \\propto p(\\text{data}|\\mu,\\vec{\\nu})\\cdot \\pi(\\vec{\\nu}_0|\\vec{\\nu})$\n",
    "\n",
    "now we will try to build the likelihood by hand for a 1-bin counting experiment.\n",
    "The data is the number of observed events $N$, and the probability is just a Poisson probability $p(N|\\lambda) = \\frac{\\lambda^N e^{-\\lambda}}{N!}$, where $\\lambda$ is the number of events expected in our signal+background model: $\\lambda = \\mu\\cdot s(\\vec{\\nu}) + b(\\vec{\\nu})$. \n",
    "\n",
    "In the expression, s and b are the numbers of expected signal and background events, which both depend on the nuisance parameters. We will start by building a simple likelihood function with one signal process and one background process. We will assume there are no nuisance parameters for now. The number of observed events in data is 15, the expected number of signal events is 5 and the expected number of background events 8.1.\n",
    "\n",
    "It is easiest to use the `RooFit` workspace factory to build our model ([this tutorial](https://root.cern/doc/master/rf511__wsfactory__basic_8py.html) has more information on the factory syntax)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cfbc021-d052-47cc-9944-d6cecda38dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = ROOT.RooWorkspace(\"w\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc910c81-4e4c-4d36-86dd-052f97ec1a99",
   "metadata": {},
   "source": [
    "We need to create an expression for the number of events in our model, $\\mu s +b$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a41a18-8e3c-4aee-8b3c-78748361bffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "w.factory('expr::n(\"mu*s +b\", mu[1.0,0,4], s[5], b[8.1])')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4496258-ec89-4f8f-9b18-5af9111ee666",
   "metadata": {},
   "source": [
    "Now we can build the likelihood, which is just our Poisson PDF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27bb0b1-e23b-4201-8917-ddde02d16369",
   "metadata": {},
   "outputs": [],
   "source": [
    "w.factory('Poisson::poisN(N[15],n)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb8c1481-9cdb-4fac-9a14-8ed31a45e1f4",
   "metadata": {},
   "source": [
    "To find the best fit value for our parameter of interest $\\mu$ we need to maximize the likelihood. In practice it is actually easier to minimize the **N**egative **l**og of the **l**ikelihood, or NLL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8250278b-53b1-4092-a18b-a675927af650",
   "metadata": {},
   "outputs": [],
   "source": [
    "w.factory('expr::NLL(\"-log(@0)\",poisN)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b1616e-9bac-41a1-a89b-58ecb303937d",
   "metadata": {},
   "source": [
    "We can now use the `RooMinimizer` to find the minimum of the NLL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b235faa-59c9-43e3-bbf2-84bcf82fa327",
   "metadata": {},
   "outputs": [],
   "source": [
    "nll = w.function(\"NLL\")\n",
    "minim = ROOT.RooMinimizer(nll)\n",
    "minim.setErrorLevel(0.5)\n",
    "minim.minimize(\"Minuit2\",\"migrad\")\n",
    "bestfitnll = nll.getVal()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dbabb40-099c-470b-a3b3-714ce700cc6d",
   "metadata": {},
   "source": [
    "Notice that we need to set the error level to 0.5 to get the uncertainties (relying on Wilks' theorem!) - note that there is a more reliable way of extracting the confidence interval (explicitly rather than relying on migrad). We will discuss this a bit later in this section."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "751b666e-903f-44e0-99db-50f8ad58fa57",
   "metadata": {},
   "source": [
    "Now we will add a nuisance parameter, *lumi*, which represents the luminosity uncertainty. It has a 2.5% effect on both the signal and the background. The parameter will be log-normally distributed: when it's 0, the normalization of the signal and background are not modified; at $+1\\sigma$ the signal and background normalizations will be multiplied by 1.025 and at $-1\\sigma$ they will be divided by 1.025.  We should modify the expression for the number of events in our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160ad1b1-090a-49ad-add7-855169a39aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = ROOT.RooWorkspace(\"w\")\n",
    "w.factory('expr::n(\"mu*s*pow(1.025,lumi)+b*pow(1.025,lumi)\", mu[1.0,0,4], s[5], b[8.1], lumi[0,-4,4])')\n",
    "w.factory('Poisson::poisN(N[15],n)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc4401b-4f36-4de3-ba0b-6fbebbe9b0eb",
   "metadata": {},
   "source": [
    "**Important**: RooFit does not allow to redefine functions with the same name in the workspace, that's why we defined a new workspace and the poisson function that depended on  n."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ccef4f1-fa6c-45da-bf06-488ca8fa58a1",
   "metadata": {},
   "source": [
    "And we add a unit gaussian constraint "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f228ded-a1d5-4654-93e2-cedeef0f12a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "w.factory('Gaussian::lumiconstr(lumi,0,1)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477f7998-7bcf-4150-a3ac-7f84aa6d8877",
   "metadata": {},
   "source": [
    "Our full likelihood will now be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390e790e-9c72-44bb-a6e8-041ffa0915d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "w.factory('PROD::likelihood(poisN,lumiconstr)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28075368-c5c4-4397-baba-dd42bf190744",
   "metadata": {},
   "source": [
    "and the NLL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b821e89-309e-491e-9b08-ed2939811cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "w.factory('expr::NLL(\"-log(@0)\",likelihood)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c6c5d1-a419-4f93-81d0-979c6cc8cfbf",
   "metadata": {},
   "source": [
    "Now we will extend our model a bit. \n",
    "\n",
    "- Expanding on what was demonstrated above, build the likelihood for $N=15$, a signal process *s* with expectation 5 events, a background *ztt* with expectation 3.7 events and a background *tt* with expectation 4.4 events. The luminosity uncertainty applies to all three processes. The signal process is further subject to a 5% log-normally distributed uncertainty *sigth*, *tt* is subject to a 6% log-normally distributed uncertainty *ttxs*, and *ztt* is subject to a 4% log-normally distributed uncertainty *zttxs*. Find the best-fit value and the associated uncertainty\n",
    "- Also perform an explicit scan of the $\\Delta$ NLL ( = log of profile likelihood ratio) and make a graph of the scan. Some example code can be found below to get you started. Hint: you'll need to perform fits for different values of mu, where mu is fixed. In `RooFit` you can set a variable to be constant as `var(\"VARNAME\").setConstant(True)`\n",
    "- From the curve that you have created by performing an explicit scan, we can extract the 68% CL interval. You can do so by eye or by writing some code to find the relevant intersections of the curve. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5819fef8-538c-4bd9-b0d0-c44d9693fea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "w = ROOT.RooWorkspace(\"w\")\n",
    "w.factory('''\n",
    "    expr::n(\n",
    "    \"mu*s*pow(1.025,lumi)*pow(1.05,sigth)+ztt*pow(1.025,lumi)*pow(1.05,zttxs)+tt*pow(1.025,lumi)*pow(1.06,ttxs)\", \n",
    "    mu[1.0,0,4], \n",
    "    s[5], \n",
    "    ztt[3.7],\n",
    "    tt[4.4],\n",
    "    lumi[0,-4,4],\n",
    "    sigth[0,-4,4],\n",
    "    zttxs[0,-4,4],\n",
    "    ttxs[0,-4,4]\n",
    "    )\n",
    "    ''')\n",
    "w.factory('Poisson::poisN(N[15],n)')\n",
    "w.factory('Gaussian::lumiconstr(lumi,0,1)')\n",
    "w.factory('Gaussian::sigthconstr(sigth,0,1)')\n",
    "w.factory('Gaussian::zttxsconstr(zttxs,0,1)')\n",
    "w.factory('Gaussian::ttxsconstr(ttxs,0,1)')\n",
    "w.factory('PROD::likelihood(poisN,lumiconstr,sigthconstr,zttxsconstr,ttxsconstr)')\n",
    "w.factory('expr::NLL(\"-log(@0)\",likelihood)')\n",
    "\n",
    "nll = w.function(\"NLL\")\n",
    "minim = ROOT.RooMinimizer(nll)\n",
    "minim.setErrorLevel(0.5)\n",
    "minim.setPrintLevel(-1)\n",
    "minim.setVerbose(False)\n",
    "minim.minimize(\"Minuit2\",\"migrad\")\n",
    "bestfitnll = nll.getVal()\n",
    "\n",
    "def profile_lr(profiled_nll, best_nll):\n",
    "    return 2*(profiled_nll - best_nll)\n",
    "\n",
    "xs = np.linspace(0., 3.5, 30)\n",
    "ys = []\n",
    "for x in xs:\n",
    "    mu = w.var(\"mu\")\n",
    "    mu.setVal(x)\n",
    "    mu.setConstant()\n",
    "    minim.minimize(\"Minuit2\",\"migrad\")\n",
    "    profiled_nll = nll.getVal()\n",
    "    ys.append(profile_lr(profiled_nll, bestfitnll))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(xs, ys, label=\"NLL scan\")\n",
    "ax.axhline(0.98, color=\"k\")\n",
    "ax.axhline(3.84, color=\"k\")\n",
    "ax.set_ylim(0, 5)\n",
    "ax.legend();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
