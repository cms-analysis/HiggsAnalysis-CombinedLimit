{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Systematic Uncertainties\n",
    "In this section, we will learn how to add systematic uncertainties to a parametric fit analysis. The python commands in this notebook are taken from the `systematics.py` script. \n",
    "\n",
    "For uncertainties which only affect the process normalisation, we can simply implement these as `lnN` uncertainties in the datacard. The file `mc_part3.root` contains the systematic-varied trees i.e. Monte-Carlo events where some systematic uncertainty source `{photonID,JEC,scale,smear}` has been varied up and down by $1\\sigma$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ROOT\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = ROOT.TFile(\"mc_part3.root\")\n",
    "f.ls()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first load the systematic-varied trees as RooDataSets and store them in a python dictionary, `mc`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define mass and weight variables\n",
    "mass = ROOT.RooRealVar(\"CMS_hgg_mass\", \"CMS_hgg_mass\", 125, 100, 180)\n",
    "weight = ROOT.RooRealVar(\"weight\",\"weight\",0,0,1)\n",
    "\n",
    "mc = {}\n",
    "\n",
    "# Load the nominal dataset\n",
    "t = f.Get(\"ggH_Tag0\")\n",
    "mc['nominal'] = ROOT.RooDataSet(\"ggH_Tag0\",\"ggH_Tag0\", t, ROOT.RooArgSet(mass,weight), \"\", \"weight\" )\n",
    "\n",
    "# Load the systematic-varied datasets\n",
    "for syst in ['JEC','photonID','scale','smear']:\n",
    "    for direction in ['Up','Down']:\n",
    "        key = \"%s%s01Sigma\"%(syst,direction)\n",
    "        name = \"ggH_Tag0_%s\"%(key)\n",
    "        t = f.Get(name)\n",
    "        mc[key] = ROOT.RooDataSet(name, name, t, ROOT.RooArgSet(mass,weight), \"\", \"weight\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The jet energy scale (JEC) and photon identification (photonID) uncertainties do not affect the shape of the $m_{\\gamma\\gamma}$ distribution i.e. they only effect the signal yield estimate. We can calculate their impact by comparing the sum of weights to the nominal data set. Note, the photonID uncertainty changes the weight of the events in the tree, whereas the JEC varied trees contain a different set of events, generated by shifting the jet energy scale in the simulation. In any case, the means for calculating the yield variations is equivalent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for syst in ['JEC','photonID']:\n",
    "    for direction in ['Up','Down']:\n",
    "        yield_variation = mc['%s%s01Sigma'%(syst,direction)].sumEntries()/mc['nominal'].sumEntries()\n",
    "        print(\"Systematic varied yield (%s,%s): %.3f\"%(syst,direction,yield_variation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can write these yield variations in the datacard with the lines:\n",
    "\n",
    "```\n",
    "CMS_scale_j           lnN      0.951/1.056      -\n",
    "CMS_hgg_phoIdMva      lnN      1.05             -   \n",
    "```\n",
    "\n",
    "* Why is the photonID uncertainty expressed as one number, whereas the JEC uncertainty is defined by two?\n",
    "\n",
    "Note in this analysis there are no systematic uncertainties affecting the background estimate (\"-\") in the datacard), as the background model has been derived directly from data.\n",
    "\n",
    "### Parametric shape uncertainties\n",
    "What about systematic uncertainties which affect the shape of the mass distribution?\n",
    "\n",
    "In a parametric analysis, we need to build the dependence directly into the model parameters. The example uncertainty sources in this tutorial are the photon energy scale and smearing uncertainties. From the names alone we can expect that the **scale** uncertainty will affect the mean of the signal Gaussian, and the **smear** uncertainty will impact the resolution (sigma). Let's first take a look at the `scaleUp01Sigma` dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model to fit the systematic-varied datasets\n",
    "mean = ROOT.RooRealVar(\"mean\", \"mean\", 125, 124, 126)\n",
    "sigma = ROOT.RooRealVar(\"sigma\", \"sigma\", 2, 1.5, 2.5)\n",
    "gaus = ROOT.RooGaussian(\"model\", \"model\", mass, mean, sigma)\n",
    "\n",
    "# Run the fits twice (second time from the best-fit of first run) to obtain more reliable results\n",
    "gaus.fitTo(mc['scaleUp01Sigma'], ROOT.RooFit.SumW2Error(True), ROOT.RooFit.PrintLevel(-1))\n",
    "gaus.fitTo(mc['scaleUp01Sigma'], ROOT.RooFit.SumW2Error(True), ROOT.RooFit.PrintLevel(-1))\n",
    "print(\"Mean = %.3f +- %.3f GeV, Sigma = %.3f +- %.3f GeV\"%(mean.getVal(),mean.getError(),sigma.getVal(),sigma.getError()) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's compare the values to the nominal fit for all systematic-varied trees. We observe a significant variation in the mean for the **scale** uncertainty, and a significant variation in sigma for the **smear** uncertainty. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First fit the nominal dataset\n",
    "gaus.fitTo(mc['nominal'], ROOT.RooFit.SumW2Error(True), ROOT.RooFit.PrintLevel(-1) )\n",
    "gaus.fitTo(mc['nominal'], ROOT.RooFit.SumW2Error(True), ROOT.RooFit.PrintLevel(-1) )\n",
    "# Save the mean and sigma values and errors to python dicts\n",
    "mean_values, sigma_values = {}, {}\n",
    "mean_values['nominal'] = [mean.getVal(),mean.getError()]\n",
    "sigma_values['nominal'] = [sigma.getVal(),sigma.getError()]\n",
    "\n",
    "# Next for the systematic varied datasets\n",
    "for syst in ['scale','smear']:\n",
    "    for direction in ['Up','Down']:\n",
    "        key = \"%s%s01Sigma\"%(syst,direction)\n",
    "        gaus.fitTo(mc[key] , ROOT.RooFit.SumW2Error(True), ROOT.RooFit.PrintLevel(-1) )\n",
    "        gaus.fitTo(mc[key], ROOT.RooFit.SumW2Error(True), ROOT.RooFit.PrintLevel(-1))\n",
    "        mean_values[key] = [mean.getVal(), mean.getError()]\n",
    "        sigma_values[key] = [sigma.getVal(), sigma.getError()]\n",
    "\n",
    "# Print the variations in mean and sigma\n",
    "for key in mean_values.keys():\n",
    "    print(\"%s: mean = %.3f +- %.3f GeV, sigma = %.3f +- %.3f GeV\"%(key,mean_values[key][0],mean_values[key][1],sigma_values[key][0],sigma_values[key][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The values tell us that the scale uncertainty (at $\\pm 1 \\sigma$) varies the signal peak mean by around 0.3%, and the smear uncertainty (at $\\pm 1 \\sigma$) varies the signal width (sigma) by around 4.5% (average of up and down variations). \n",
    "\n",
    "Now we need to bake these effects into the parametric signal model. The mean of the Gaussian was previously defined as:\n",
    "\n",
    "$$ \\mu = m_H + \\delta$$\n",
    "\n",
    "We introduce the nuisance parameter `nuisance_scale` = $\\eta$ to account for a shift in the signal peak mean using:\n",
    "\n",
    "$$ \\mu = (m_H + \\delta) \\cdot (1+0.003\\eta)$$\n",
    "\n",
    "At $\\eta = +1 (-1)$ the signal peak mean will shift up (down) by 0.3%. To build this into the RooFit signal model we simply define a new parameter, $\\eta$, and update the definition of the mean formula variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the workspace with systematic variations\n",
    "MH = ROOT.RooRealVar(\"MH\", \"MH\", 125, 120, 130 )\n",
    "MH.setConstant(True)\n",
    "\n",
    "# Define formula for mean of Gaussian\n",
    "dMH = ROOT.RooRealVar(\"dMH_ggH_Tag0\", \"dMH_ggH_Tag0\", 0, -5, 5 )\n",
    "eta = ROOT.RooRealVar(\"nuisance_scale\", \"nuisance_scale\", 0, -5, 5)\n",
    "eta.setConstant(True)\n",
    "mean_formula = ROOT.RooFormulaVar(\"mean_ggH_Tag0\", \"mean_ggH_Tag0\", \"(@0+@1)*(1+0.003*@2)\", ROOT.RooArgList(MH,dMH,eta))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Why do we set the nuisance parameter to constant at this stage?\n",
    "\n",
    "Similar for the width introducing a nuisance parameter, $\\chi$:\n",
    "\n",
    "$$ \\sigma = \\sigma \\cdot (1+0.045\\chi)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = ROOT.RooRealVar(\"sigma_ggH_Tag0_nominal\", \"sigma_ggH_Tag0_nominal\", 2, 1, 5)\n",
    "chi = ROOT.RooRealVar(\"nuisance_smear\", \"nuisance_smear\", 0, -5, 5)\n",
    "chi.setConstant(True)\n",
    "sigma_formula = ROOT.RooFormulaVar(\"sigma_ggH_Tag0\", \"sigma_ggH_Tag0\", \"@0*(1+0.045*@1)\", ROOT.RooArgList(sigma,chi))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now fit the new model to the signal Monte-Carlo dataset, build the normalisation object and save the workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define Gaussian\n",
    "model = ROOT.RooGaussian( \"model_ggH_Tag0\", \"model_ggH_Tag0\", mass, mean_formula, sigma_formula )\n",
    "\n",
    "# Fit model to MC\n",
    "model.fitTo( mc['nominal'], ROOT.RooFit.SumW2Error(True), ROOT.RooFit.PrintLevel(-1) )\n",
    "\n",
    "# Build signal model normalisation object\n",
    "xs_ggH = ROOT.RooRealVar(\"xs_ggH\", \"Cross section of ggH in [pb]\", 48.58 )\n",
    "br_gamgam = ROOT.RooRealVar(\"BR_gamgam\", \"Branching ratio of Higgs to gamma gamma\", 0.0027 )\n",
    "eff = mc['nominal'].sumEntries()/(xs_ggH.getVal()*br_gamgam.getVal())\n",
    "eff_ggH_Tag0 = ROOT.RooRealVar(\"eff_ggH_Tag0\", \"Efficiency for ggH events to land in Tag0\", eff )\n",
    "# Set values to be constant\n",
    "xs_ggH.setConstant(True)\n",
    "br_gamgam.setConstant(True)\n",
    "eff_ggH_Tag0.setConstant(True)\n",
    "# Define normalisation component as product of these three variables\n",
    "norm_sig = ROOT.RooProduct(\"model_ggH_Tag0_norm\", \"Normalisation term for ggH in Tag 0\", ROOT.RooArgList(xs_ggH,br_gamgam,eff_ggH_Tag0))\n",
    "\n",
    "# Set shape parameters of model to be constant (i.e. fixed in fit to data)\n",
    "dMH.setConstant(True)\n",
    "sigma.setConstant(True)\n",
    "\n",
    "# Build new signal model workspace with signal normalisation term. \n",
    "f_out = ROOT.TFile(\"workspace_sig_with_syst.root\", \"RECREATE\")\n",
    "w_sig = ROOT.RooWorkspace(\"workspace_sig\",\"workspace_sig\")\n",
    "getattr(w_sig, \"import\")(model)\n",
    "getattr(w_sig, \"import\")(norm_sig)\n",
    "w_sig.Print()\n",
    "w_sig.Write()\n",
    "f_out.Close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final step is to add the parametric uncertainties as Gaussian-constrained nuisance parameters into the datacard. The syntax means the Gaussian constraint term in the likelihood function will have a mean of 0 and a width of 1.\n",
    "```\n",
    "nuisance_scale        param    0.0    1.0\n",
    "nuisance_smear        param    0.0    1.0\n",
    "```\n",
    "* Try adding these lines to `datacard_part1_with_norm.txt`, along with the lines for the JEC and photonID yield uncertainties above, and compiling with the `text2workspace` command. Open the workspace and look at its contents. You will need to change the signal process workspace file name in the datacard to point to the new workspace (`workspace_sig_with_syst.root`).\n",
    "* Can you see the new objects in the compiled datacard that have been created for the systematic uncertainties? What do they correspond to?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Compile datacard with systematic uncertainties included"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now run a fit with the systematic uncertainties included. The option `--saveSpecifiedNuis` can be called to save the postfit nuisance parameter values in the combine output limit tree. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "combine -M MultiDimFit datacard_part1_with_norm.root -m 125 --freezeParameters MH --saveWorkspace \\\n",
    "-n .bestfit.with_syst --saveSpecifiedNuis CMS_scale_j,CMS_hgg_phoIdMva,nuisance_scale,nuisance_smear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* What do the postfit values of the nuisances tell us here? You can check them by opening the output file (`root higgsCombine.bestfit.with_syst.MultiDimFit.mH125.root`) and running `limit->Show(0)`.\n",
    "* Try plotting the postfit mass distribution (as detailed in part 2). Do you notice any difference?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uncertainty breakdown\n",
    "A more complete datacard with additional nuisance parameters is stored in `datacard_part3.txt`. We will use this datacard for the rest of part 3. Open the text file and have a look at the contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's open the datacard and take a look\n",
    "with open(\"datacard_part3.txt\",\"r\") as f:\n",
    "    lines = f.readlines()\n",
    "    \n",
    "print(\"\".join(lines))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following line has been appended to the end of the datacard to define the set of theory nuisance parameters. This will come in handy when calculating the uncertainty breakdown.\n",
    "```\n",
    "theory group = BR_hgg QCDscale_ggH pdf_Higgs_ggH alphaS_ggH UnderlyingEvent PartonShower\n",
    "```\n",
    "Compile the datacard and run an observed `MultiDimFit` likelihood scan over the signal strength, r:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "text2workspace.py datacard_part3.txt -m 125\n",
    "\n",
    "combine -M MultiDimFit datacard_part3.root -m 125 --freezeParameters MH \\\n",
    "-n .scan.with_syst --algo grid --points 20 --setParameterRanges r=0.5,2.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our aim is to break down the total uncertainty into the systematic and statistical components. To get the statistical-uncertainty-only scan it should be as simple as freezing the nuisance parameters in the fit... right? \n",
    "\n",
    "Try it by adding `,allConstrainedNuisances` to the `--freezeParameters` option. This will freeze all (constrained) nuisance parameters in the fit. You can also feed in regular expressions with wildcards using `rgx{.*}`. For instance to freeze only the `nuisance_scale` and `nuisance_smear` you could run with `--freezeParameters MH,rgx{nuisance_.*}`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "combine -M MultiDimFit datacard_part3.root -m 125 --freezeParameters MH,allConstrainedNuisances \\\n",
    "-n .scan.with_syst.statonly --algo grid --points 20 --setParameterRanges r=0.5,2.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can plot the two likelihood scans on the same axis with the command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "plot1DScan.py higgsCombine.scan.with_syst.MultiDimFit.mH125.root --main-label \"With systematics\" \\\n",
    "--main-color 1 --others higgsCombine.scan.with_syst.statonly.MultiDimFit.mH125.root:\"Stat-only\":2 -o part3_scan_v0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets open the png file and plot it here\n",
    "Image(filename='part3_scan_v0.png', width=500) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Can you spot the problem? \n",
    "\n",
    "The nuisance parameters introduced into the model have pulled the best-fit signal strength point! Therefore we cannot simply subtract the uncertainties in quadrature to get an estimate for the systematic/statistical uncertainty breakdown. \n",
    "\n",
    "The correct approach is to freeze the nuisance parameters to their respective best-fit values in the stat-only scan. We can do this by first saving a postfit workspace with all nuisance parameters profiled in the fit. Then we load the postfit snapshot values of the nuisance parameters (with the option `--snapshotName MultiDimFit`) from the combine output of the previous step, and then freeze the nuisance parameters for the stat-only scan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "combine -M MultiDimFit datacard_part3.root -m 125 --freezeParameters MH \\\n",
    "-n .bestfit.with_syst --setParameterRanges r=0.5,2.5 --saveWorkspace\n",
    "\n",
    "combine -M MultiDimFit higgsCombine.bestfit.with_syst.MultiDimFit.mH125.root -m 125 \\\n",
    "--freezeParameters MH,allConstrainedNuisances -n .scan.with_syst.statonly_correct --algo grid --points 20 \\\n",
    "--setParameterRanges r=0.5,2.5 --snapshotName MultiDimFit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding the option `--breakdown syst,stat` to the `plot1DScan.py` command will automatically calculate the uncertainty breakdown for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "plot1DScan.py higgsCombine.scan.with_syst.MultiDimFit.mH125.root --main-label \"With systematics\" \\\n",
    "--main-color 1 --others higgsCombine.scan.with_syst.statonly_correct.MultiDimFit.mH125.root:\"Stat-only\":2 \\\n",
    "-o part3_scan_v1 --breakdown syst,stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets open the png file and plot it here\n",
    "Image(filename='part3_scan_v1.png', width=500) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also freeze groups of nuisance parameters defined in the datacard with the option `--freezeNuisanceGroups`. Let's run a scan freezing only the theory uncertainties (using the nuisance group we defined in the datacard):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "combine -M MultiDimFit higgsCombine.bestfit.with_syst.MultiDimFit.mH125.root -m 125 --freezeParameters MH \\\n",
    "--freezeNuisanceGroups theory -n .scan.with_syst.freezeTheory --algo grid --points 20 \\\n",
    "--setParameterRanges r=0.5,2.5 --snapshotName MultiDimFit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To breakdown the total uncertainty into the theory, experimental and statistical components we can then use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "plot1DScan.py higgsCombine.scan.with_syst.MultiDimFit.mH125.root --main-label Total --main-color 1 \\\n",
    "--others higgsCombine.scan.with_syst.freezeTheory.MultiDimFit.mH125.root:\"Freeze theory\":4 \\\n",
    "higgsCombine.scan.with_syst.statonly_correct.MultiDimFit.mH125.root:\"Stat-only\":2 \\\n",
    "-o part3_scan_v2 --breakdown theory,exp,stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets open the png file and plot it here\n",
    "Image(filename='part3_scan_v2.png', width=500) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These methods are not limited to this particular grouping of systematics. We can use the above procedure to assess the impact of any nuisance parameter(s) on the signal strength confidence interval. \n",
    "* Try and calculate the contribution to the total uncertainty from the luminosity estimate using this approach.\n",
    "\n",
    "### Impacts\n",
    "It is often useful/required to check the impacts of the nuisance parameters (NP) on the parameter of interest, r. The impact of a NP is defined as the shift $\\Delta r$ induced as the NP, $\\theta$, is fixed to its $\\pm1\\sigma$ values, with all other parameters profiled as normal. More information can be found in the combine documentation via this [link](https://cms-analysis.github.io/HiggsAnalysis-CombinedLimit/part3/nonstandard/#nuisance-parameter-impacts).\n",
    "\n",
    "Let's calculate the impacts for our analysis. We can use the `combineTool.py` from the `CombineHarvester` package to automate the scripts. The impacts are calculated in a few stages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# 1) Do an initial fit for the parameter of interest, adding the `--robustFit 1` option:\n",
    "combineTool.py -M Impacts -d datacard_part3.root -m 125 --freezeParameters MH -n .impacts \\\n",
    "--setParameterRanges r=0.5,2.5 --doInitialFit --robustFit 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* What does the option `--robustFit 1` do? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# 2) Next perform a similar scan for each NP with the `--doFits` option. This may take a few minutes\n",
    "combineTool.py -M Impacts -d datacard_part3.root -m 125 --freezeParameters MH \\\n",
    "-n .impacts --setParameterRanges r=0.5,2.5 --doFits --robustFit 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# 3) Collect the outputs from the previous step and write the results to a json file:\n",
    "combineTool.py -M Impacts -d datacard_part3.root -m 125 --freezeParameters MH \\\n",
    "-n .impacts --setParameterRanges r=0.5,2.5 -o impacts_part3.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# 4) Produce a plot summarising the nuisance parameter values and impacts:\n",
    "plotImpacts.py -i impacts_part3.json -o impacts_part3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open the output pdf file. There is a lot of information in these plots, which can be of invaluable use to analysers in understanding the fit. Do you understand everything that the plot is showing?\n",
    "* Which NP has the highest impact on the signal strength measurement?\n",
    "* Which NP is pulled the most in the fit to data? What does this information imply about the signal model mean in relation to the data?\n",
    "* Which NP is the most constrained in the fit to the data? What does it mean for a nuisance parameter to be constrained?\n",
    "* Try adding the option `--summary` to the impacts plotting command. This is a nice new feature in combine!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
