<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    
    
    
    <link rel="shortcut icon" href="../../img/favicon.ico">

    
    <title>Simplified Likelihoods - Combine</title>
    

    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.12.0/css/all.css">
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.12.0/css/v4-shims.css">
    <link rel="stylesheet" href="//cdn.jsdelivr.net/npm/hack-font@3.3.0/build/web/hack.min.css">
    <link href='//rsms.me/inter/inter.css' rel='stylesheet' type='text/css'>
    <link href='//fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,700italic,400,300,600,700&subset=latin-ext,latin' rel='stylesheet' type='text/css'>
    <link href="../../css/bootstrap-custom.min.css" rel="stylesheet">
    <link href="../../css/base.min.css" rel="stylesheet">
    <link href="../../css/cinder.min.css" rel="stylesheet">

    
        
        <link rel="stylesheet" href="//cdn.jsdelivr.net/gh/highlightjs/cdn-release@9.18.0/build/styles/github.min.css">
        
    
    <link href="../../mystyle.css" rel="stylesheet">

    <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
            <script src="https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js"></script>
            <script src="https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js"></script>
        <![endif]-->

    

     
</head>

<body>

    <div class="navbar navbar-default navbar-fixed-top" role="navigation">
    <div class="container">

        <!-- Collapsed navigation -->
        <div class="navbar-header">
            <!-- Expander button -->
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            

            <!-- Main title -->

            
              <a class="navbar-brand" href="../..">Combine</a>
            
        </div>

        <!-- Expanded navigation -->
        <div class="navbar-collapse collapse">
                <!-- Main navigation -->
                <ul class="nav navbar-nav">
                
                
                    <li >
                        <a href="../..">Home</a>
                    </li>
                
                
                
                    <li class="dropdown">
                        <a href="#" class="dropdown-toggle" data-toggle="dropdown">Setting up the analysis <b class="caret"></b></a>
                        <ul class="dropdown-menu">
                        
                            
<li >
    <a href="../../part2/settinguptheanalysis/">Preparing the datacard</a>
</li>

                        
                            
<li >
    <a href="../../part2/physicsmodels/">Physics models</a>
</li>

                        
                            
<li >
    <a href="../../part2/bin-wise-stats/">Automatic MC statistical uncertainties</a>
</li>

                        
                        </ul>
                    </li>
                
                
                
                    <li class="dropdown active">
                        <a href="#" class="dropdown-toggle" data-toggle="dropdown">Running combine <b class="caret"></b></a>
                        <ul class="dropdown-menu">
                        
                            
<li >
    <a href="../runningthetool/">Running the tool</a>
</li>

                        
                            
<li >
    <a href="../commonstatsmethods/">Common statistical methods</a>
</li>

                        
                            
<li >
    <a href="../nonstandard/">Advanced use cases</a>
</li>

                        
                            
<li class="active">
    <a href="./">Simplified Likelihoods</a>
</li>

                        
                            
<li >
    <a href="../regularisation/">Unfolding & regularization</a>
</li>

                        
                            
<li >
    <a href="../validation/">Validating datacards</a>
</li>

                        
                            
<li >
    <a href="../debugging/">Debugging fit failures</a>
</li>

                        
                        </ul>
                    </li>
                
                
                
                    <li >
                        <a href="../../part4/usefullinks/">Links & FAQ</a>
                    </li>
                
                
                
                    <li class="dropdown">
                        <a href="#" class="dropdown-toggle" data-toggle="dropdown">Tutorials <b class="caret"></b></a>
                        <ul class="dropdown-menu">
                        
                            
<li >
    <a href="../../part5/roofit/">RooFit Basics</a>
</li>

                        
                            
<li >
    <a href="../../part5/longexercise/">Exercise: main features</a>
</li>

                        
                            
<li >
    <a href="../../part5/longexerciseanswers/">Solutions to long exercise</a>
</li>

                        
                        </ul>
                    </li>
                
                
                </ul>

            <ul class="nav navbar-nav navbar-right">
                    <li>
                        <a href="#" data-toggle="modal" data-target="#mkdocs_search_modal">
                            <i class="fas fa-search"></i> Search
                        </a>
                    </li>
                    <li >
                        <a rel="prev" href="../nonstandard/">
                            <i class="fas fa-arrow-left"></i> Previous
                        </a>
                    </li>
                    <li >
                        <a rel="next" href="../regularisation/">
                            Next <i class="fas fa-arrow-right"></i>
                        </a>
                    </li>
                    <li>
                        <a href="https://github.com/cms-analysis/HiggsAnalysis-CombinedLimit/edit/main/docs/part3/simplifiedlikelihood.md"><i class="fab fa-github"></i> Edit on GitHub</a>
                    </li>
            </ul>
        </div>
    </div>
</div>

    <div class="container">
        
        
        <div class="col-md-3"><div class="bs-sidebar hidden-print affix well" role="complementary">
    <ul class="nav bs-sidenav">
        <li class="first-level active"><a href="#procedure-for-creating-and-validating-simplified-likelihood-inputs">Procedure for creating and validating simplified likelihood inputs</a></li>
            <li class="second-level"><a href="#requirements">Requirements</a></li>
                
            <li class="second-level"><a href="#producing-covariance-for-recasting">Producing covariance for recasting</a></li>
                
            <li class="second-level"><a href="#produce-simplified-likelihood-inputs">Produce simplified likelihood inputs</a></li>
                
            <li class="second-level"><a href="#validating-the-simplified-likelihood-approach">Validating the simplified likelihood approach</a></li>
                
                <li class="third-level"><a href="#convert-root-to-python">Convert ROOT to Python</a></li>
                <li class="third-level"><a href="#run-a-likelihood-scan-with-the-sl">Run a likelihood scan with the SL</a></li>
            <li class="second-level"><a href="#example-using-tutorial-datacard">Example using tutorial datacard</a></li>
                
    </ul>
</div></div>
        <div class="col-md-9" role="main">

<h1 id="procedure-for-creating-and-validating-simplified-likelihood-inputs">Procedure for creating and validating simplified likelihood inputs</h1>
<p>This page is to give a brief outline for the creation of (potentially aggregated) predictions and their covariance to facilitate external reinterpretation using the simplified likelihood (SL) approach. Instructions for validating the simplified likelihood method (detailed in the note <a href="https://cds.cern.ch/record/2242860/files/NOTE2017_001.pdf">here</a> and <a href="https://arxiv.org/abs/1809.05548">here</a>) in the linear mode are also given.</p>
<h2 id="requirements">Requirements</h2>
<p>You need an up to date version of combine. Note You should use the latest release of combine for the exact commands on this page. You should be using combine tag <code>v9.0.0</code> or higher or the latest version of the <code>112x</code> branch to follow these instructions.  </p>
<p>You will find the python scripts needed to convert combine outputs into simplified likelihood inputs under <code>test/simplifiedLikelihood</code></p>
<p>If you're using the <code>102x</code> branch (not reccomended), then you can obtain these scripts from here by running: </p>
<pre><code>curl -s https://raw.githubusercontent.com/nucleosynthesis/work-tools/master/sparse-checkout-SL-ssh.sh &gt; checkoutSL.sh
bash checkoutSL.sh
ls work-tools/stats-tools
</code></pre>
<p>If you also want to validate your inputs and perform fits/scans using them, you can use the package <a href="https://gitlab.cern.ch/SimplifiedLikelihood/SLtools/-/blob/master/README.md">SLtools</a> for this.</p>
<pre><code>git clone https://gitlab.cern.ch/SimplifiedLikelihood/SLtools.git
</code></pre>
<h2 id="producing-covariance-for-recasting">Producing covariance for recasting</h2>
<p>Producing the necessary predictions and covariance for recasting varies depending on whether control regions are explicitly included in the datacard when running fits. Instructions for cases where the control regions <em>are</em> and <em>are not</em> included are detailed below.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>The instructions below will calculate moments based on the assumption that <span class="arithmatex"><span class="MathJax_Preview">E[x]=\hat{x}</span><script type="math/tex">E[x]=\hat{x}</script></span>, i.e it will use the maximum likelihood estimators for the yields as the expectation values. If instead you want to use the full definition of the moments, you can run the <code>FitDiagnostics</code> method with the <code>-t</code> option and include <code>--savePredictionsPerToy</code> and remove the other options, which will produce a tree of the toys in the output from which moments can be calculated. </p>
</div>
<details>
<summary><b>Type A - Control regions included in datacard</b></summary>

For an example datacard 'datacard.txt' including two signal channels 'Signal1' and 'Signal2', make the workspace including the masking flags

<pre><code>
text2workspace.py --channel-masks --X-allow-no-signal --X-allow-no-background datacard.txt -o datacard.root
</pre></code>

Run the fit making the covariance (output saved as `fitDiagnostics.root`) masking the Signal channel. Note that all signal channels must be masked!

<pre><code>
combine datacard.root -M FitDiagnostics --saveShapes --saveWithUnc --numToysForShape 2000 --setParameters mask_Signal1=1,mask_Signal2=1 --saveOverall  -N Name
</pre></code>
Where "Name" can be specified by you.

Outputs including predictions and covariance will be saved in `fitDiagnosticsName.root` folder `shapes_fit_b`

</details>

<details>
<summary><b>Type B - Control regions not included in datacard</b></summary>

For an example datacard 'datacard.txt' including two signal channels 'Signal1' and 'Signal2', make the workspace

<pre><code>
text2workspace.py --X-allow-no-signal --X-allow-no-background datacard.txt -o datacard.root
</pre></code>

Run the fit making the covariance (output saved as `fitDiagnosticsName.root`) setting no signal contribution in the prefit. Note we *must* set `--preFitValue 0` in this case since we will be using the pre-fit uncertainties for the covariance calculation and we don't want to include the  uncertainties on the signal. 

<pre><code>
combine datacard.root -M FitDiagnostics --saveShapes --saveWithUnc --numToysForShape 2000 --saveOverall --preFitValue 0   -n Name
</pre></code>
 Where "Name" can be specified by you.

Outputs including predictions and covariance will be saved in `fitDiagnosticsName.root` folder `shapes_prefit`

In order to also pull out the signal yields corresponding to `r=1` (in case you want to run the validation step later), you also need to produce a second file with the prefit value set to 1. For this you don't need to run many toys so to save time, just set `--numToysForShape` to some low value. 

<pre><code>
combine datacard.root -M FitDiagnostics --saveShapes --saveWithUnc --numToysForShape 1 --saveOverall --preFitValue 1   -n Name2
</pre></code>

</details>

<p>You should check that the order of the bins in the covariance matrix is as expected.</p>
<h2 id="produce-simplified-likelihood-inputs">Produce simplified likelihood inputs</h2>
<p>Head over to the <code>test/simplifiedLikelihoods</code> directory inside your combine area. The following instructions depend on whether you are aggregating or not aggregating your signal regions. Choose the instructions for your case. </p>
<details>
<summary><b>Not Aggregating</b></summary>    
Run the `makeLHInputs.py` script to prepare the inputs for the simplified likelihood. The filter flag can be used to select only signal regions based on the channel names. To include all channels don't include the filter flag.

The SL input must NOT include any control regions which were not masked in the fit.

If your analysis is Type B (i.e everything in the datacard is a signal region), then you can just run 

<pre><code>
python makeLHInputs.py -i fitDiagnosticsName.root -o SLinput.root 
</pre></code>

If necessary (i.e as in Type B analyses) you may also need to run the same on the run where the prefit value was set to 1. 

<pre><code>
python makeLHInputs.py -i fitDiagnosticsName2.root -o SLinput2.root 
</pre></code>

If you instead have a Type A analysis (some of the regions are control regions that were used to fit but not masked) then you should add the option `--filter SignalName` where `SignalName` is some string that defines the signal regions in your datacards (eg "SR" is a common name for these).

Note: If your signal regions cannot be easily identified by a string, follow the instructions below for aggregating but define only one channel for each aggregate region which will maintain the full information and won't actually aggregate any regions.

</details>

<details>
<summary><b>Aggregating</b></summary>    
If aggregating based on covariance edit the config file `aggregateCFG.py` to define aggregate regions based on channel names, note that wildcards are supported. You can then make likelihood inputs using

<pre><code>
python makeLHInputs.py -i fitDiagnosticsName.root -o SLinput.root --config aggregateCFG.py
</pre></code>

</details>

<p>At this point you now have the inputs as ROOT files necessary to publish and run the simplified likelihood. </p>
<h2 id="validating-the-simplified-likelihood-approach">Validating the simplified likelihood approach</h2>
<p>The simplified likelihood relies on several assumptions (detailed in the documentation at the top). To test the validity for your analysis, statistical results between combine and the simplified likelihood can be compared. </p>
<p>We will use the package <a href="https://gitlab.cern.ch/SimplifiedLikelihood/SLtools/-/blob/master/README.md">SLtools</a> for this. The first step is to convert the ROOT files into python configs to run in the tool. </p>
<h3 id="convert-root-to-python">Convert ROOT to Python</h3>
<p>If you followed the steps above, you have all of the histograms already necessary to generate the python configs. The script <code>test/simplifiedLikelihoods/convertSLRootToPython.py</code>  can be used to do the conversion. Just provide the following options when running with python.</p>
<ul>
<li><code>-O/--outname</code> : The output python file containing the model (default is <code>test.py</code>)</li>
<li><code>-s/--signal</code> : The signal histogram, should be of format <code>file.root:location/to/histogram</code></li>
<li><code>-b/--background</code> : The background histogram, should be of format <code>file.root:location/to/histogram</code></li>
<li><code>-d/--data</code> : The data TGraph, should be of format <code>file.root:location/to/graph</code></li>
<li><code>-c/--covariance</code> : The covariance TH2 histogram, should be of format <code>file.root:location/to/histogram</code></li>
</ul>
<p>For example to get the correct output from a Type B analysis with no Aggregating, you can run </p>
<pre><code class="language-sh">python test/simplifiedLikelihoods/convertSLRootToPython.py -O mymodel.py -s SLinput.root:shapes_prefit/total_signal  -b SLinput.root:shapes_prefit/total_M2 d -d SLinput.root:shapes_prefit/total_data -c SLinput.root:shapes_prefit/total_M2
</code></pre>
<p>The output will be a python file with the right format for the SL tool. You can mix different ROOT files for these inputs. Note that the SLtools package also has some tools to covert <code>.yaml</code> based inputs into the python config for you.</p>
<h3 id="run-a-likelihood-scan-with-the-sl">Run a likelihood scan with the SL</h3>
<p>If you have checked out the <a href="https://gitlab.cern.ch/SimplifiedLikelihood/SLtools/-/blob/master/README.md">SLtools</a>, you can create a simple python script as the one below to produce a scan of the simplified likelihood from your inputs.</p>
<pre><code class="language-python">#! /usr/bin/env python
import simplike as sl

exec(open(&quot;mymodel.py&quot;).read())
slp1 = sl.SLParams(background, covariance, obs=data, sig=signal)

import numpy as np
npoints = 50
mus = np.arange(-0.5, 2, (2+0.5)/npoints)
tmus1 = [slp1.tmu(mu) for mu in mus]
from matplotlib import pyplot as plt
plt.plot(mus,tmus1)
plt.show()
</code></pre>
<p>Where, the <code>mymodel.py</code> config is a simple python file defined as;</p>
<ul>
<li><code>data</code> : A python array of observed data, one entry per bin.</li>
<li><code>background</code> : A python array of expected background, one entry per bin.</li>
<li><code>covariance</code> : A python array of the covariance between expected backgrounds. The format is a flat array which is converted into a 2D array inside the tool</li>
<li><code>signal</code> : A python array of the expected signal, one entry per bin. This should be replaced with whichever signal model you are testing.</li>
</ul>
<p>This <code>model.py</code> can also just be the output of the previous section converted from the ROOT files for you.</p>
<p>The example below is from the note CMS-NOTE-2017-001</p>
<details>
<summary><b>Show example</b></summary>

<pre><code>
import numpy
import array

name = "CMS-NOTE-2017-001 dummy model"
nbins = 8
data = array.array('d',[1964,877,354,182,82,36,15,11])
background = array.array('d',[2006.4,836.4,350.,147.1,62.0,26.2,11.1,4.7])
signal = array.array('d',[47,29.4,21.1,14.3,9.4,7.1,4.7,4.3])
covariance = array.array('d', [ 18774.2, -2866.97, -5807.3, -4460.52, -2777.25, -1572.97, -846.653, -442.531, -2866.97, 496.273, 900.195, 667.591, 403.92, 222.614, 116.779, 59.5958, -5807.3, 900.195, 1799.56, 1376.77, 854.448, 482.435, 258.92, 134.975, -4460.52, 667.591, 1376.77, 1063.03, 664.527, 377.714, 203.967, 106.926, -2777.25, 403.92, 854.448, 664.527, 417.837, 238.76, 129.55, 68.2075, -1572.97, 222.614, 482.435, 377.714, 238.76, 137.151, 74.7665, 39.5247, -846.653, 116.779, 258.92, 203.967, 129.55, 74.7665, 40.9423, 21.7285, -442.531, 59.5958, 134.975, 106.926, 68.2075, 39.5247, 21.7285, 11.5732])
</pre></code>
</details>

<h2 id="example-using-tutorial-datacard">Example using tutorial datacard</h2>
<p>For this example, we'll use the tutorial datacard <code>data/tutorials/longexercise/datacard_part3.txt</code>. This datacard is of <strong>Type B</strong> since there are no control regions (all regions are signal regions). </p>
<p>First, we'll create the binary file (run <code>text2workspace</code>)</p>
<pre><code>text2workspace.py --X-allow-no-signal --X-allow-no-background data/tutorials/longexercise/datacard_part3.txt  -m 200
</code></pre>
<p>And next, we'll generate the covariance between the bins of the background model. </p>
<pre><code>combine data/tutorials/longexercise/datacard_part3.root -M FitDiagnostics --saveShapes --saveWithUnc --numToysForShape 10000 --saveOverall --preFitValue 0   -n SimpleTH1 -m 200

combine data/tutorials/longexercise/datacard_part3.root -M FitDiagnostics --saveShapes --saveWithUnc --numToysForShape 1 --saveOverall --preFitValue 1   -n SimpleTH1_Signal1 -m 200
</code></pre>
<p>We will also want to compare our scan to that from the full likelihood, which we can get as usual from combine. </p>
<pre><code>combine -M MultiDimFit data/tutorials/longexercise/datacard_part3.root --rMin -0.5 --rMax 2 --algo grid -n SimpleTH1 -m 200
</code></pre>
<p>Next, since we don't plan to aggregate any of the bins, we'll follow the instructions for this and pick out the right covariance matrix.</p>
<pre><code>python test/simplifiedLikelihoods/makeLHInputs.py -i fitDiagnosticsSimpleTH1.root -o SLinput.root 

python test/simplifiedLikelihoods/makeLHInputs.py -i fitDiagnosticsSimpleTH1_Signal1.root -o SLinput_Signal1.root 
</code></pre>
<p>We now have everything we need to provide the simplified likelihood inputs. E.G</p>
<pre><code>$ root -l SLinput.root
root [0] .ls

Attaching file SLinput.root as _file0...
(TFile *) 0x3667820
root [1] .ls
TFile**         SLinput.root
 TFile*         SLinput.root
  KEY: TDirectoryFile   shapes_fit_b;1  shapes_fit_b
  KEY: TDirectoryFile   shapes_prefit;1 shapes_prefit
  KEY: TDirectoryFile   shapes_fit_s;1  shapes_fit_s
</code></pre>
<p>We can convert this to a python module that we can use to run a scan with the SLtools package. Note, since we have a <strong>Type B</strong> datacard, we'll be using the <em>pre-fit</em> covariance matrix. Also, this means we want to take the signal from the file where the prefit value of <code>r</code> was 1. </p>
<pre><code>python test/simplifiedLikelihoods/convertSLRootToPython.py -O mymodel.py -s SLinput_Signal1.root:shapes_prefit/total_signal  -b SLinput.root:shapes_prefit/total_M1-d SLinput.root:shapes_prefit/total_data -c SLinput.root:shapes_prefit/total_M2
</code></pre>
<p>Let's compare the profiled likelihood scans from our simplified likelihood (using the python file we just created) and from the full likelihood (that we created with combine.). For the former, we need to first checkout the SLtools package </p>
<pre><code>git clone https://gitlab.cern.ch/SimplifiedLikelihood/SLtools.git
mv higgsCombineSimpleTH1.MultiDimFit.mH200.root SLtools/ 
mv mymodel.py SLtools/
cd SLtools
</code></pre>
<p>The script below will create a plot of the comparison for us. </p>
<pre><code class="language-python">#! /usr/bin/env python
import simplike as sl

exec(open(&quot;mymodel.py&quot;).read())

slp1 = sl.SLParams(background, covariance, obs=data, sig=signal)

import ROOT 
fi = ROOT.TFile.Open(&quot;higgsCombineSimpleTH1.MultiDimFit.mH200.root&quot;)
tr = fi.Get(&quot;limit&quot;)

points = []
for i in range(tr.GetEntries()):
  tr.GetEntry(i)
  points.append([tr.r,2*tr.deltaNLL])
points.sort()

mus2=[pt[0] for pt in points]
tmus2=[pt[1] for pt in points]

import numpy as np
npoints = 50
mus1 = np.arange(-0.5, 2, (2+0.5)/npoints)
tmus1 = [slp1.tmu(mu) for mu in mus1]

from matplotlib import pyplot as plt
plt.plot(mus1,tmus1,label='simplified likelihood')
plt.plot(mus2,tmus2,label='full likelihood')
plt.legend()
plt.xlabel(&quot;$\mu$&quot;)
plt.ylabel(&quot;$-2\Delta \ln L$&quot;)

plt.savefig(&quot;compareLH.pdf&quot;)
</code></pre>
<p>This will produce a figure like the one below. </p>
<p><img alt="" src="../SLexample.jpg" /></p>
<p>It is also possible to include the 3rd moment of each bin to improve the precision of the simplified likelihood [ <a href="https://link.springer.com/article/10.1007/JHEP04(2019)064">JHEP 64 2019</a> ]. The necessary information is stored in the outputs from combine so you just need to include the option <code>-t SLinput.root:shapes_prefit/total_M3</code> in the options list for <code>convertSLRootToPython.py</code> to  include this in the model file. The 3rd moment information can be included in SLtools by using <code>sl.SLParams(background, covariance, third_moment, obs=data, sig=signal)</code></p></div>
        
        
    </div>

    
      <footer class="col-md-12 text-center">
          
          
            <hr>
            <p>
            <small>Documentation built with <a href="http://www.mkdocs.org/">MkDocs</a>.</small>
            </p>
          

          
          
      </footer>
    
    <script src="//ajax.googleapis.com/ajax/libs/jquery/1.12.4/jquery.min.js"></script>
    <script src="../../js/bootstrap-3.0.3.min.js"></script>

    
    <script src="//cdn.jsdelivr.net/gh/highlightjs/cdn-release@9.18.0/build/highlight.min.js"></script>
        
    <script>hljs.initHighlightingOnLoad();</script>
    

    <script>var base_url = "../.."</script>
    
    <script src="../../js/base.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML"></script>
    <script src="../../search/main.js"></script>

    <div class="modal" id="mkdocs_search_modal" tabindex="-1" role="dialog" aria-labelledby="searchModalLabel" aria-hidden="true">
    <div class="modal-dialog modal-lg">
        <div class="modal-content">
            <div class="modal-header">
                <button type="button" class="close" data-dismiss="modal">
                    <span aria-hidden="true">&times;</span>
                    <span class="sr-only">Close</span>
                </button>
                <h4 class="modal-title" id="searchModalLabel">Search</h4>
            </div>
            <div class="modal-body">
                <p>
                    From here you can search these documents. Enter
                    your search terms below.
                </p>
                <form>
                    <div class="form-group">
                        <input type="text" class="form-control" placeholder="Search..." id="mkdocs-search-query" title="Type search term here">
                    </div>
                </form>
                <div id="mkdocs-search-results"></div>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div><div class="modal" id="mkdocs_keyboard_modal" tabindex="-1" role="dialog" aria-labelledby="keyboardModalLabel" aria-hidden="true">
    <div class="modal-dialog">
        <div class="modal-content">
            <div class="modal-header">
                <h4 class="modal-title" id="keyboardModalLabel">Keyboard Shortcuts</h4>
                <button type="button" class="close" data-dismiss="modal"><span aria-hidden="true">&times;</span><span class="sr-only">Close</span></button>
            </div>
            <div class="modal-body">
              <table class="table">
                <thead>
                  <tr>
                    <th style="width: 20%;">Keys</th>
                    <th>Action</th>
                  </tr>
                </thead>
                <tbody>
                  <tr>
                    <td class="help shortcut"><kbd>?</kbd></td>
                    <td>Open this help</td>
                  </tr>
                  <tr>
                    <td class="next shortcut"><kbd>n</kbd></td>
                    <td>Next page</td>
                  </tr>
                  <tr>
                    <td class="prev shortcut"><kbd>p</kbd></td>
                    <td>Previous page</td>
                  </tr>
                  <tr>
                    <td class="search shortcut"><kbd>s</kbd></td>
                    <td>Search</td>
                  </tr>
                </tbody>
              </table>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div>
    </body>

</html>
